import os
import pysam
#import pull_files as p
#import boto3 as boto3
from snakemake.remote.S3 import RemoteProvider as S3RemoteProvider

AWS_ACCESS_KEY_ID = os.environ["aws_access_key_id"]
AWS_SECRET_ACCESS_KEY_ID = os.environ["aws_secret_access_key"]

S3 = S3RemoteProvider(access_key_id = AWS_ACCESS_KEY_ID, secret_access_key = AWS_SECRET_ACCESS_KEY_ID)

if config == {}:
    configfile: "config.qc.json"

if not os.path.exists("log"):
    os.makedirs("log")

SAMPLE_PATH = config["sample_bam"]
SAMPLE_BAI = config["sample_bai"]
SAMPLE_NAME = config["sample_name"]
FINAL_OUTPUT = config["final_output"]
WGS_OUTPUT = config["wgs_output"]

SAMPLES = {}
SAMPLES[SAMPLE_NAME] = SAMPLE_PATH

REF_GENOME = config["ref_genome"]
PICARD = config["picard"]
TARGETS = config["targets"]

localrules: all, copy_final, flagstat, hybridization_metrics, wgs_metrics, convert_to_bam, filter_on_greater_than_10_percent_mismatch, extract_mitochondria

rule all:
    input: SAMPLE_PATH, expand("{sample}.flagstat.txt", sample = SAMPLES), expand("{sample}.MT.sam", sample = SAMPLES), expand("{sample}.MT.clean.sam", sample = SAMPLES), expand("{sample}.MT.clean.bam", sample = SAMPLES), expand("{sample}_wgs_metrics.txt", sample = SAMPLES), expand("{sample}_hybridization_metrics.txt", sample = SAMPLES), expand("{sample}_per_target_coverage.txt", sample = SAMPLES), expand("{sample}.copy.finished.txt", sample=SAMPLES)
    params: sge_opts="-l mfree=20G -N run_all" 

rule copy_final:
    input: expand("{sample}.MT.clean.bam", sample = SAMPLE_NAME), expand("{sample}.flagstat.txt", sample = SAMPLE_NAME), expand("{sample}_wgs_metrics.txt", sample = SAMPLE_NAME), expand("{sample}_hybridization_metrics.txt", sample = SAMPLE_NAME), expand("{sample}_per_target_coverage.txt", sample = SAMPLE_NAME)
    output: "{sample}.copy.finished.txt"
    params: prefix="{sample}", sge_opts = "-l mfree=8G"
    shell:
        """
        aws s3 cp {input[0]} s3://{FINAL_OUTPUT}
        aws s3 cp {input[1]} s3://{FINAL_OUTPUT}
        aws s3 cp {input[2]} s3://{FINAL_OUTPUT}
        aws s3 cp {input[3]} s3://{FINAL_OUTPUT}
        aws s3 cp {input[4]} s3://{FINAL_OUTPUT}
        aws s3 cp {params.prefix}.convert.to.bam.log s3://{FINAL_OUTPUT}
        aws s3 cp {params.prefix}.flagstat.log s3://{FINAL_OUTPUT}
        aws s3 cp {params.prefix}.extract.mito.log s3://{FINAL_OUTPUT}
        aws s3 cp {params.prefix}.hybridization.metrics.log s3://{FINAL_OUTPUT}
        aws s3 cp {params.prefix}.filter.mismatches.log s3://{FINAL_OUTPUT}
        aws s3 cp {params.prefix}.wgs.metrics.log s3://{FINAL_OUTPUT}

        touch {output}
        """

rule flagstat:
    input: SAMPLE_PATH
    output: "{sample}.flagstat.txt"
    log: "{sample}.flagstat.log"
    params: sge_opts="-l mfree=20G -N run_flagstat -cwd"
    shell: """
        date &> {log}
        #module load modules modules-init modules-gs
        #module load samtools/1.2

        samtools flagstat {input} > {output}
        
        date >> {log}
    """

rule hybridization_metrics:
    input: SAMPLE_PATH
    output: "{sample}_hybridization_metrics.txt", "{sample}_per_target_coverage.txt"
    log: "{sample}.hybridization.metrics.log"
    params: sge_opts="-l h_vmem=6G -pe serial 8 -N run_hyb_metrics -cwd"
    shell: """
        date &> {log}

        java -Xmx50g -XX:ParallelGCThreads=8 -jar {PICARD} CalculateHsMetrics REFERENCE_SEQUENCE={REF_GENOME} INPUT={input} OUTPUT={output[0]} PER_TARGET_COVERAGE={output[1]} BAIT_INTERVALS={TARGETS} TARGET_INTERVALS={TARGETS} VALIDATION_STRINGENCY=LENIENT

        date >> {log}
    """


rule wgs_metrics:
    input: SAMPLE_PATH
    output: "{sample}_wgs_metrics.txt"
    log: "{sample}.wgs.metrics.log"
    params: sge_opts="-l h_vmem=20G -N run_wgs_metrics -cwd"
    shell: """
        date &> {log}

        java -Xmx15g -jar {PICARD} CollectWgsMetrics REFERENCE_SEQUENCE={REF_GENOME} INPUT={input} OUTPUT={output} VALIDATION_STRINGENCY=LENIENT
        date >> {log}
    """

rule convert_to_bam:
    input: "{sample}.MT.clean.sam"
    log: "{sample}.convert.to.bam.log"
    output: "{sample}.MT.clean.bam"
    params: sge_opts="-l mfree=20G -N convert_to_bam -cwd"
    shell: """
        date &> {log}

        samtools view -Sb {input} > {output}

        date >> {log}
    """


rule filter_on_greater_than_10_percent_mismatch:
    input: "{sample}.MT.sam"
    output: "{sample}.MT.clean.sam"
    log: "{sample}.filter.mismatches.log"
    params: sge_opts="-l mfree=20G -N filter_on_greater_than_10_percent_mismatch -cwd"
    shell: """
        date &> {log}

        egrep -w 'NM:i:1||NM:i:2||NM:i:3||NM:i:4||NM:i:5||NM:i:6||NM:i:7||NM:i:8||NM:i:9||NM:i:10||NM:i:11||NM:i:12||NM:i:13||NM:i:14||' {input} | grep -v 'NNNNNNNNNN' > {output}

        date >> {log}

    """

rule extract_mitochondria:
    input: SAMPLE_PATH
    output: "{sample}.MT.sam"
    log: "{sample}.extract.mito.log"
    params: sge_opts="-l mfree=10G -N extract_mitochondria -cwd"
    shell: """
        date &> {log}
 
        #module load modules modules-init modules-gs
        #module load samtools/1.2

        samtools view -h {input[0]} MT > {output}

        date >> {log}

    """

rule get_files_from_s3:
    input: S3.remote(SAMPLE_PATH, keep_local=True), S3.remote(REF_GENOME, keep_local=True), S3.remote(REF_GENOME + ".fai", keep_local=True), S3.remote(SAMPLE_BAI, keep_local=True), S3.remote(TARGETS, keep_local=True)
    output: touch(SAMPLE_PATH), touch(REF_GENOME), touch(REF_GENOME + ".fai"), touch(SAMPLE_BAI), touch(TARGETS)
    run:
        pass



#rule get_files_from_requester_pay_bucket:
#    input: p.copy_from_requester_pay_bucket(SAMPLE_PATH) , p.copy_from_requester_pay_bucket(SAMPLE_BAI)
#    output: touch(SAMPLE_PATH) , touch(SAMPLE_BAI)
#    run :
#        pass
#    shell: """python pull_files.py --sample_file {input[0]} ; python pull_files.py --sample_file {input[1]}"""
